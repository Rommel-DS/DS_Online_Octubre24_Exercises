{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cabecera.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Masterclass: Streamlit-Replicate**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Chatbot con Streamlit y Replicate  \n",
    "\n",
    "Adaptado y actualizado de [*streamlit-replicate-app*](https://github.com/sfc-gh-cnantasenamat/streamlit-replicate-app)\n",
    "y de [*llama2-chatbot*](https://github.com/a16z-infra/llama2-chatbot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "En este taller aprenderemos a crear un chatbot utilizando Streamlit como interfaz y Replicate para acceder a potentes modelos de lenguaje como Llama 3 y Claude.\n",
    "\n",
    "### Requisitos previos\n",
    "- Python 3.8 o superior\n",
    "- Una cuenta en [Replicate](https://replicate.com) para obtener una API Key\n",
    "\n",
    "### Instalaci√≥n\n",
    "Para empezar, crea un nuevo repositorio en tu perfil de GitHub para este proyecto y sincron√≠zalo en tu equipo.  \n",
    "\n",
    "Una vez creado, copia en su interior el contenido de la carpeta `proyecto-base`. Esta carpeta contiene la estructura inicial del proyecto con la configuraci√≥n necesaria, incluyendo un fichero `.streamlit` con los archivos `toml` de configuraci√≥n b√°sica.  \n",
    "\n",
    "[Extra: ¬øQu√© es un TOML?](https://es.wikipedia.org/wiki/TOML)\n",
    "\n",
    "Ahora puedes crear un entorno virtual dentro de tu proyecto e instalar las dependencias necesarias:  \n",
    "\n",
    "```bash\n",
    "pip install streamlit replicate\n",
    "```\n",
    "\n",
    "### Ejecuci√≥n de la aplicaci√≥n\n",
    "Una vez creada, podr√°s ejecutar tu aplicaci√≥n con:\n",
    "\n",
    "```bash\n",
    "streamlit run chatbot_app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 1: Configuraci√≥n inicial**\n",
    "\n",
    "Una vez completada la fase previa de instalaci√≥n, abre el archivo `chatbot_app.py` en tu IDE favorito.  \n",
    "\n",
    "Ver√°s que ya contiene la configuraci√≥n inicial. Si no, puedes crearlo con el siguiente c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import replicate\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Configuraci√≥n inicial\n",
    "st.set_page_config(\n",
    "    page_title=\"Streamlit Replicate Chatbot\",\n",
    "    page_icon=\":robot:\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 2: A√±adir CSS personalizado**\n",
    "\n",
    "Podemos mejorar la apariencia de nuestra aplicaci√≥n con un poco de CSS personalizado.\n",
    "\n",
    "[Extra: ¬øQu√© es CSS?](https://es.wikipedia.org/wiki/CSS)\n",
    "\n",
    "El siguiente fragmento de c√≥digo nos permite:\n",
    "\n",
    "- Ajustar el tama√±o de fuente en las √°reas de texto a 13px para una mejor lectura.\n",
    "- Establecer ese mismo tama√±o de fuente (13px) en los componentes desplegables para mayor consistencia.\n",
    "- Ocultar elementos \"innecesarios\" como el pie de p√°gina de Streamlit y el men√∫ principal de la aplicaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS personalizado\n",
    "custom_css = \"\"\"\n",
    "    <style>\n",
    "        .stTextArea textarea {font-size: 13px;}\n",
    "        div[data-baseweb=\"select\"] > div {font-size: 13px !important;}\n",
    "        footer {visibility: hidden;}\n",
    "        #MainMenu {visibility: hidden;}\n",
    "    </style>\n",
    "\"\"\"\n",
    "st.markdown(custom_css, unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 3: Definir la informaci√≥n de los modelos disponibles**\n",
    "\n",
    "Crearemos un diccionario con la informaci√≥n de los modelos que utilizaremos, este diccionario nos permite:\n",
    "\n",
    "- Centralizar informaci√≥n sobre cada modelo.\n",
    "- Acceder f√°cilmente a los endpoints de la API de Replicate.\n",
    "- Guardar metadatos importantes como: \n",
    "  - Enlaces a documentaci√≥n.\n",
    "  - Compatibilidad con par√°metros (como top_p).\n",
    "  - Requerimientos m√≠nimos de tokens.\n",
    "- Simplificar cambios entre modelos diferentes.\n",
    "- Escalar la aplicaci√≥n sin modificar el c√≥digo principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n de modelos\n",
    "model_info = {\n",
    "    'meta-llama-3-8b-instruct': {\n",
    "        'endpoint': 'meta/meta-llama-3-8b-instruct',\n",
    "        'doc_link': 'https://replicate.com/meta/meta-llama-3-8b-instruct',\n",
    "        'uses_top_p': True,\n",
    "        'min_tokens': 64\n",
    "    },\n",
    "    'meta-llama-3-70b-instruct': {\n",
    "        'endpoint': 'meta/meta-llama-3-70b-instruct',\n",
    "        'doc_link': 'https://replicate.com/meta/meta-llama-3-70b-instruct',\n",
    "        'uses_top_p': True,\n",
    "        'min_tokens': 64\n",
    "    },\n",
    "    'meta-llama-3.1-405b-instruct': {\n",
    "        'endpoint': 'meta/meta-llama-3.1-405b-instruct',\n",
    "        'doc_link': 'https://replicate.com/meta/meta-llama-3.1-405b-instruct',\n",
    "        'uses_top_p': True,\n",
    "        'min_tokens': 64\n",
    "    },\n",
    "    'meta-llama-4-17b-maverick-instruct': {\n",
    "        'endpoint': 'meta/llama-4-maverick-instruct',\n",
    "        'doc_link': 'https://replicate.com/meta/llama-4-maverick-instruct',\n",
    "        'uses_top_p': True,\n",
    "        'min_tokens': 64\n",
    "    },\n",
    "    'anthropic-claude-3.7-sonnet': {\n",
    "        'endpoint': 'anthropic/claude-3.7-sonnet',\n",
    "        'doc_link': 'https://replicate.com/anthropic/claude-3.7-sonnet',\n",
    "        'uses_top_p': False,\n",
    "        'min_tokens': 1024\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 4: Inicializaci√≥n de variables en el estado de la sesi√≥n**\n",
    "\n",
    "Streamlit utiliza un estado de sesi√≥n para mantener variables entre ejecuciones. Inicializamos las variables que necesitaremos:\n",
    "\n",
    "[Extra: Aprende m√°s sobre Session State en Streamlit](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializaci√≥n de variables\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"How may I assist you today?\"}]\n",
    "if \"model\" not in st.session_state:\n",
    "    st.session_state.model = 'meta/meta-llama-3-8b-instruct'\n",
    "if \"selected_model\" not in st.session_state:\n",
    "    st.session_state.selected_model = 'meta-llama-3-8b-instruct'\n",
    "if \"temperature\" not in st.session_state:\n",
    "    st.session_state.temperature = 0.7\n",
    "if \"top_p\" not in st.session_state:\n",
    "    st.session_state.top_p = 0.9\n",
    "if \"max_tokens\" not in st.session_state:\n",
    "    st.session_state.max_tokens = 512\n",
    "if \"pre_prompt\" not in st.session_state:\n",
    "    st.session_state.pre_prompt = \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 5: Dise√±o de la barra lateral - Estructura b√°sica y API key**\n",
    "\n",
    "Comenzamos con la estructura b√°sica de la barra lateral y la configuraci√≥n de la API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barra lateral\n",
    "with st.sidebar:\n",
    "    st.title('ü§ñ Streamlit Replicate Chatbot')\n",
    "    \n",
    "    # API key\n",
    "    if 'REPLICATE_API_TOKEN' in st.secrets:\n",
    "        st.success('API key already provided!', icon='‚úÖ')\n",
    "        replicate_api = st.secrets['REPLICATE_API_TOKEN']\n",
    "    else:\n",
    "        replicate_api = st.text_input('Enter Replicate API token:', type='password')\n",
    "        if not (replicate_api.startswith('r8_') and len(replicate_api)==40):\n",
    "            st.warning('Please enter your credentials!', icon='‚ö†Ô∏è')\n",
    "        else:\n",
    "            st.success('Proceed to entering your prompt message!', icon='üëâ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que no hayas copiado los archivos de la carpeta `proyecto-base`, a partir de este punto para ejecutar la aplicaci√≥n necesitar√°s crear un archivo `.streamlit/secrets.toml` con tu API key de Replicate:\n",
    "\n",
    "```toml\n",
    "REPLICATE_API_TOKEN = \"tu_api_key_de_replicate\"\n",
    "```\n",
    "\n",
    "Esto nos permitir√° testear la aplicaci√≥n durante su desarrollo, pero recuerda que **nunca debes subir tus secretos a GitHub**.  \n",
    "\n",
    "Cuando despleguemos nuestro chatbot podremos decidir si facilitamos una API key (y asumimos los gastos del chatbot) o dejamos que los usuarios utilicen sus propias API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 6: Barra lateral - Selector de modelos**\n",
    "\n",
    "Implementamos el selector de modelos para permitir al usuario cambiar entre diferentes LLMs, recuerda que es parte de la barra lateral as√≠ que cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Selecci√≥n del modelo\n",
    "    st.subheader('Models and parameters')\n",
    "    model_options = list(model_info.keys())\n",
    "    \n",
    "    selected_model = st.sidebar.selectbox(\n",
    "        'Choose a model', model_options, \n",
    "        index=model_options.index(st.session_state.selected_model)\n",
    "    )\n",
    "    \n",
    "    # Forzar recarga para aplicar cambios de modelo\n",
    "    if selected_model != st.session_state.selected_model:\n",
    "        st.session_state.selected_model = selected_model\n",
    "        st.session_state.model = model_info[selected_model]['endpoint']\n",
    "        st.rerun()\n",
    "    \n",
    "    current_model = st.session_state.selected_model\n",
    "    current_model_info = model_info[current_model]\n",
    "\n",
    "    # Link de documentaci√≥n\n",
    "    doc_link = current_model_info['doc_link']\n",
    "    st.markdown(f\"üëâ [Learn more about this model]({doc_link}) üëà\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 7: Barra lateral - Configuraci√≥n de par√°metros del modelo**\n",
    "\n",
    "A√±adimos controles deslizantes para ajustar algunos de los par√°metros de generaci√≥n que hemos explicado en la Parte 1, recuerda que son parte de la barra lateral as√≠ que cuidado con las indentaciones:\n",
    "\n",
    "### Deslizador de Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Deslizador de Temperatura\n",
    "    st.session_state.temperature = st.sidebar.slider(\n",
    "        'temperature', \n",
    "        min_value=0.0, \n",
    "        max_value=5.0, \n",
    "        value=st.session_state.temperature, \n",
    "        step=0.05\n",
    "    )\n",
    "    if st.session_state.temperature >= 1:\n",
    "        st.info('Values exceeding 1 produce more creative and random outputs as well as increased likelihood of hallucination.')\n",
    "    if st.session_state.temperature < 0.1:\n",
    "        st.warning('Values approaching 0 produce deterministic outputs. The recommended starting value is 0.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deslizador de Top-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Deslizador de Top-p\n",
    "    st.session_state.top_p = st.sidebar.slider(\n",
    "        'top_p', \n",
    "        min_value=0.00, \n",
    "        max_value=1.0, \n",
    "        value=st.session_state.top_p, \n",
    "        step=0.05, \n",
    "        disabled=not current_model_info['uses_top_p']\n",
    "    )\n",
    "    if not current_model_info['uses_top_p']:\n",
    "        st.warning(f'{current_model} does not use the top_p parameter.')\n",
    "    else:\n",
    "        if st.session_state.top_p < 0.5:\n",
    "            st.warning('Low top_p values (<0.5) can make output more focused but less diverse. Recommended starting value is 0.9')\n",
    "        if st.session_state.top_p == 1.0:\n",
    "            st.info('A top_p value of 1.0 means no nucleus sampling is applied (considers all tokens).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deslizador de Max Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Deslizador de Max tokens\n",
    "    min_tokens = current_model_info['min_tokens']\n",
    "    st.session_state.max_tokens = st.sidebar.slider(\n",
    "        'max_length', \n",
    "        min_value=min_tokens, \n",
    "        max_value=4096, \n",
    "        value=max(min_tokens, st.session_state.max_tokens), \n",
    "        step=8\n",
    "    )\n",
    "    if min_tokens > 64:\n",
    "        st.warning(f'{current_model} requires at least {min_tokens} input tokens.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 8: Barra lateral - System Prompt Editable**\n",
    "\n",
    "A√±adimos un √°rea de texto para editar el prompt de sistema y as√≠ poder definir el comportamiento de nuestro chatbot, recuerda que es parte de la barra lateral as√≠ que cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Prompt de sistema editable\n",
    "    st.subheader(\"System Prompt\")\n",
    "    new_prompt = st.text_area(\n",
    "        'Edit the prompt that guides the model:',\n",
    "        st.session_state.pre_prompt,\n",
    "        height=100\n",
    "    )\n",
    "    if new_prompt != st.session_state.pre_prompt and new_prompt.strip():\n",
    "        st.session_state.pre_prompt = new_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 9: Barra lateral - Bot√≥n de limpiar historial**\n",
    "\n",
    "Implementamos un bot√≥n para limpiar el historial de chat, esto borrar√° los mensajes del estado de sesi√≥n de modo que \"reiniciar√°\" la conversaci√≥n, recuerda que es parte de la barra lateral as√≠ que cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Bot√≥n de limpiar historial \n",
    "    def clear_chat_history():\n",
    "        st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"How may I assist you today?\"}]\n",
    "    st.button('Clear Chat', on_click=clear_chat_history, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *¬°Por fin hemos terminado la barra lateral!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 10: Configuraci√≥n de la API de Replicate**\n",
    "\n",
    "Configuramos la API key para Replicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API token\n",
    "os.environ['REPLICATE_API_TOKEN'] = replicate_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 11: Funci√≥n para generar respuestas**\n",
    "\n",
    "Ahora definimos la funci√≥n que se comunicar√° con Replicate para obtener respuestas del modelo. Esta funci√≥n es el coraz√≥n de nuestro chatbot y realiza varias tareas clave:\n",
    "\n",
    "1. **Formatea el historial de conversaci√≥n**:\n",
    "   - Comienza con el system prompt (instrucciones iniciales para el modelo) y tras ello agrega todo el historial de mensajes con formato \"User:\" y \"Assistant:\".\n",
    "   - Esto permite que el modelo tenga contexto completo de la conversaci√≥n.\n",
    "\n",
    "2. **Configura los par√°metros de generaci√≥n**:\n",
    "   - Prepara los par√°metros que controlar√°n el comportamiento del modelo incluyendo prompt, temperatura, longitud m√°xima y penalizaci√≥n por repetici√≥n.\n",
    "   - A√±ade el par√°metro top_p solo si el modelo seleccionado lo soporta.\n",
    "\n",
    "3. **Transmite la respuesta en tiempo real**:\n",
    "   - Utiliza la funci√≥n `stream` de Replicate para obtener tokens de respuesta gradualmente e implementa un **generador** que permite mostrar la respuesta token por token.\n",
    "   - Esto crea una experiencia m√°s natural donde el usuario ve la respuesta form√°ndose progresivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaci√≥n de respuesta\n",
    "def generate_response(prompt_input):\n",
    "    string_dialogue = st.session_state.pre_prompt + \"\\n\\n\"\n",
    "    for dict_message in st.session_state.messages:\n",
    "        if dict_message[\"role\"] == \"user\":\n",
    "            string_dialogue += \"User: \" + dict_message[\"content\"] + \"\\n\\n\"\n",
    "        else:\n",
    "            string_dialogue += \"Assistant: \" + dict_message[\"content\"] + \"\\n\\n\"\n",
    "    \n",
    "    # Par√°metros base\n",
    "    input_params = {\n",
    "        \"prompt\": f\"{string_dialogue}User: {prompt_input}\\n\\nAssistant: \",\n",
    "        \"temperature\": st.session_state.temperature,\n",
    "        \"max_tokens\": st.session_state.max_tokens,\n",
    "        \"repetition_penalty\": 1,\n",
    "    }\n",
    "    \n",
    "    # A√±adir top_p solo si el modelo lo utiliza\n",
    "    current_model = st.session_state.selected_model\n",
    "    if model_info[current_model]['uses_top_p']:\n",
    "        input_params[\"top_p\"] = st.session_state.top_p\n",
    "    \n",
    "    # Stream de respuestas\n",
    "    for event in replicate.stream(st.session_state.model, input=input_params):\n",
    "        yield str(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Generadores en Python\n",
    "\n",
    "Los generadores son funciones especiales en Python que permiten devolver valores de manera secuencial sin tener que almacenarlos todos en memoria a la vez. Se definen usando la palabra clave `yield`.\n",
    "\n",
    "#### Caracter√≠sticas principales\n",
    "\n",
    "- **Lazy Execution**: Solo generan valores cuando se solicitan, ahorrando memoria.\n",
    "- **Mantienen estado**: \"Recuerdan\" su estado entre llamadas, pausando su ejecuci√≥n y retom√°ndola donde se qued√≥.\n",
    "- **Ideales para grandes secuencias**: Perfectos para procesar grandes conjuntos de datos de manera eficiente.\n",
    "- **Iterables**: Pueden usarse en bucles for, comprensiones de listas, y otras construcciones que esperan iterables.\n",
    "\n",
    "#### Ejemplo en nuestra aplicaci√≥n\n",
    "\n",
    "```python\n",
    "# Generador que transmite respuestas del modelo\n",
    "def generate_response(prompt_input):\n",
    "    # Preparaci√≥n de los par√°metros...\n",
    "    \n",
    "    # Stream de respuestas usando un generador\n",
    "    for event in replicate.stream(\n",
    "        st.session_state.model, input=input_params\n",
    "        ):\n",
    "        yield str(event)\n",
    "\n",
    "# Uso del generador para mostrar respuestas token a token\n",
    "response = generate_response(prompt)\n",
    "full_response = st.write_stream(response)  # Procesa cada elemento a medida que se genera\n",
    "```\n",
    "\n",
    "Este patr√≥n nos permite mostrar la respuesta del modelo en tiempo real, token por token, creando una experiencia m√°s fluida e interactiva para el usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 12: Interfaz de chat**\n",
    "\n",
    "Finalmente, creamos la interfaz de chat que mostrar√° los mensajes y permitir√° al usuario interactuar con el chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar mensajes\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# Entrada del usuario\n",
    "if prompt := st.chat_input(\"Type your message here...\", disabled=not replicate_api):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "\n",
    "# Generar respuesta\n",
    "if st.session_state.messages and st.session_state.messages[-1][\"role\"] == \"user\":\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = generate_response(st.session_state.messages[-1][\"content\"])\n",
    "            full_response = st.write_stream(response)\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Operador Morsa (Walrus Operator) en Python\n",
    "\n",
    "El operador morsa (`:=`) fue introducido en Python 3.8 y permite asignar valores a variables como parte de una expresi√≥n. Su apodo \"walrus\" (morsa) viene de su apariencia visual que recuerda a los colmillos (\"tusks\") de este animal.\n",
    "\n",
    "#### Usos principales\n",
    "\n",
    "- **Asignaci√≥n y evaluaci√≥n en una sola expresi√≥n**: Permite asignar un valor a una variable y usarlo inmediatamente.\n",
    "- **Reduce c√≥digo repetitivo**: Evita c√°lculos o llamadas a funciones duplicadas.\n",
    "- **Mejora la legibilidad**: Hace que el c√≥digo sea m√°s conciso en ciertas situaciones.\n",
    "\n",
    "#### Ejemplo en nuestra aplicaci√≥n de Streamlit\n",
    "\n",
    "```python\n",
    "# Sin operador morsa\n",
    "prompt = st.chat_input(\"Type your message here...\")\n",
    "if prompt:\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "# Con operador morsa\n",
    "if prompt := st.chat_input(\"Type your message here...\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "```\n",
    "\n",
    "Este operador es especialmente √∫til en condicionales, bucles y comprensiones de listas donde necesitamos asignar y utilizar un valor en la misma expresi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 13: Configuraci√≥n para despliegue**\n",
    "\n",
    "Para desplegar tu aplicaci√≥n en Streamlit Cloud:\n",
    "\n",
    "1. Sube el c√≥digo completo a tu repositorio de GitHub.\n",
    "2. Con√©ctate a [Streamlit Cloud](https://streamlit.io/cloud).\n",
    "3. Selecciona tu repositorio, la rama y el archivo principal.\n",
    "4. Configura tus secretos en la interfaz de Streamlit Cloud (puedes acceder desde el men√∫ de tres puntos de tu aplicaci√≥n).\n",
    "5. Es hora de desplegar tu aplicaci√≥n, pero antes echa un ojo al √∫ltimo paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **√öltimo Paso: A√±adir un sistema de autenticaci√≥n (opcional)**\n",
    "\n",
    "Si quieres proteger tu aplicaci√≥n con un sistema de autenticaci√≥n, puedes a√±adir el siguiente c√≥digo justo despu√©s de las importaciones y la configuraci√≥n inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar autenticaci√≥n\n",
    "if \"authenticated\" not in st.session_state:\n",
    "    st.session_state.authenticated = False\n",
    "\n",
    "if not st.session_state.authenticated:\n",
    "    st.title(\"üîê Inicie sesi√≥n para continuar\")\n",
    "    \n",
    "    # Obtener credenciales\n",
    "    try:\n",
    "        correct_username = st.secrets['USERNAME']\n",
    "        correct_password = st.secrets['PASSWORD']\n",
    "        \n",
    "        username = st.text_input(\"Username\")\n",
    "        password = st.text_input(\"Password\", type=\"password\")\n",
    "        \n",
    "        if st.button(\"Login\"):\n",
    "            if username == correct_username and password == correct_password:\n",
    "                st.session_state.authenticated = True\n",
    "                st.success(\"Login successful!\")\n",
    "                time.sleep(1.0)\n",
    "                st.rerun()\n",
    "            else:\n",
    "                st.error(\"Invalid username or password\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error accessing secrets. Make sure you've set up .streamlit/secrets.toml file\")\n",
    "\n",
    "        # Bypass para desarrollo\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Opciones para desarrollo\")\n",
    "        st.warning(\"‚ö†Ô∏è Estas opciones solo deben usarse en entorno de desarrollo\")\n",
    "        \n",
    "        if st.button(\"Continuar sin autenticaci√≥n (Modo Desarrollo)\", \n",
    "                    type=\"primary\", \n",
    "                    help=\"Permite acceder a la aplicaci√≥n sin credenciales durante desarrollo\"):\n",
    "            st.session_state.authenticated = True\n",
    "            st.success(\"Accediendo en modo desarrollo...\")\n",
    "            time.sleep(1.0)\n",
    "            st.rerun()\n",
    "    \n",
    "    # Detener la app si usuario no est√° autenticado\n",
    "    st.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar el sistema de autenticaci√≥n, deber√°s a√±adir las credenciales a tu archivo `.streamlit/secrets.toml` (**IMPORTANTE, recuerda no subir nunca tus secretos a GitHub**):\n",
    "\n",
    "```toml\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"password\"\n",
    "REPLICATE_API_TOKEN = \"tu_api_key_de_replicate\"\n",
    "```\n",
    "\n",
    "De manera opcional tambi√©n podr√°s a√±adir un bot√≥n de logout a la barra lateral, lo puedes a√±adir en la barra lateral despu√©s del bot√≥n de Borrar Historial, y recuerda tener cuidado con las indentaciones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Bot√≥n de cerrar sesi√≥n \n",
    "    def logout():\n",
    "        st.session_state.authenticated = False\n",
    "    st.button('Logout', on_click=logout, use_container_width=True, type=\"primary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Si bien este es un m√©todo de autenticaci√≥n sencillo, puedes explorar otras formas para securizar tus aplicaciones, como por ejemplo usando plataformas de terceros m√°s robustas como [Auth0](https://auth0.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hayas a√±adido la autenticaci√≥n, solo debes repetir el Paso 13: Configuraci√≥n para el Despliegue y..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **¬°Felicidades!**  \n",
    "\n",
    "Has creado un chatbot b√°sico con Streamlit y Replicate que puede ser desplegado y protegido con una autenticaci√≥n sencilla."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
